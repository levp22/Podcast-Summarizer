{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPEN_AI_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get video transcript or audio file if video has no captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from datetime import date\n",
    "\n",
    "videos = open(\"inputs.txt\", \"r\")\n",
    "video_obj = {}\n",
    "\n",
    "for video in videos:\n",
    "    # Get YouTube video\n",
    "    yt = YouTube(video)\n",
    "    video_obj[yt.title] = { \"author\": yt.author, \"transcribed_on\": date.today() }\n",
    "    caption=YouTubeTranscriptApi.get_transcript(yt.video_id, languages=['en'])\n",
    "\n",
    "    # Get video transcription, if none exist, download audio (last stream is guaranteed English)\n",
    "    if not caption:\n",
    "        streams = yt.streams.filter(only_audio=True, file_extension=\"mp4\")\n",
    "        streams[-1].download(\"audio_files\")\n",
    "    else:\n",
    "        f = open(\"transcripts/\" + yt.title + \".txt\", \"w\")\n",
    "        for obj in caption:\n",
    "            f.write(obj['text'])\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribe audio files (if they exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "audio_files = os.fsencode(\"audio_files\")\n",
    "\n",
    "for file in os.listdir(audio_files):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".mp4\"):\n",
    "        title = filename.replace(\".mp4\", \"\")\n",
    "\n",
    "        # convert mp4 file to wav (16-bit)\n",
    "        new_filename = title + \".wav\"\n",
    "        subprocess.run([\n",
    "            'ffmpeg',\n",
    "            '-i', os.path.join(\"audio_files\", filename),\n",
    "            '-ar', '16000',\n",
    "            '-ac', '1',\n",
    "            '-c:a', 'pcm_s16le',\n",
    "            os.path.join(\"audio_files\", new_filename)\n",
    "        ])\n",
    "\n",
    "        # call local whisper model\n",
    "        result = subprocess.check_output([\n",
    "            './main',\n",
    "            '-f', '../Podcast-Summarizer/audio_files/' + new_filename\n",
    "        ], cwd=\"../whisper.cpp\")\n",
    "\n",
    "        f = open(\"transcripts/\" + title + \".txt\", \"w\")\n",
    "        f.write(result.decode(sys.stdout.encoding).strip())\n",
    "        f.close()\n",
    "\n",
    "print(video_obj)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your 'transcripts' directory\n",
    "directory_path = 'transcripts'\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check if the file is a .txt file\n",
    "    if filename.endswith('.txt'):\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        file_path2 = os.path.join('other', 'example.txt')\n",
    "        # Open and read the file\n",
    "        example_file=open(file_path2, 'r')\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            string_length = len(content)\n",
    "            midpoint = string_length // 2  # Using integer division to find the middle index\n",
    "            combined_message = \"use the following to help dictate formatting and how to structure answers, do not use any of the specific content\" + \"\\n\" + example_file.read()\n",
    "            # Split the string into two halves\n",
    "            first_half = content[:midpoint]\n",
    "            second_half = content[midpoint:]\n",
    "            first = openai.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an investment analyst for a family office who has been tasked with summarizing podcast transcripts for your boss so he can make strategic investment insights.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Please summarize the following podcast transcript for me in as much detail as possible - approximately 4000 words. Focus on the key points discussed, including the main arguments, insights, and takeaways. Additionally, identify any interesting quotes or counter-arguments presented. Please present in very detailed bullet point form, be sure to never miss a single point\"},\n",
    "                {\"role\": \"user\", \"content\": first_half},\n",
    "\n",
    "                {\"role\": \"user\", \"content\": \"there should be two sections in the output, the high level takeaways of each subject which includes key quotes, and then a detailed breakdown section as noted by the next prompt, try to stay away from generally saying what was talked about and instead focus on the specific details mentioned with some quotes and further information\"},\n",
    "               #  {\"role\": \"user\", \"content\": \"it should include a section of high level key takeaways, some of which are crucial quotes but also include some specific takeaways from the whole thing - approximately 10 of them, then a section of a deep breakdown of the entire transcript that includes a header for each subject that is talked about in the podcast and include 5 detailed bullets for each subject, try to stay away from generally saying what was talked about and instead focus on the specific details mentioned with some quotes and further information\"},\n",
    "                {\"role\": \"user\", \"content\": combined_message}\n",
    "            ]\n",
    "            )\n",
    "            print(first.choices[0].message.content)\n",
    "            print(\"first half done\")\n",
    "            second = openai.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an investment analyst for a family office who has been tasked with summarizing podcast transcripts for your boss so he can make strategic investment insights.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Please summarize the following podcast transcript for me in as much detail as possible - approximately 4000 words. Focus on the key points discussed, including the main arguments, insights, and takeaways. Additionally, identify any interesting quotes or counter-arguments presented. Please present in very detailed bullet point form, be sure to never miss a single point\"},\n",
    "                {\"role\": \"user\", \"content\": second_half},\n",
    "\n",
    "                {\"role\": \"user\", \"content\": \"there should be two sections in the output, the high level takeaways of each subject which includes key quotes, and then a detailed breakdown section as noted by the next prompt, try to stay away from generally saying what was talked about and instead focus on the specific details mentioned with some quotes and further information\"},\n",
    "               #  {\"role\": \"user\", \"content\": \"it should include a section of high level key takeaways, some of which are crucial quotes but also include some specific takeaways from the whole thing - approximately 10 of them, then a section of a deep breakdown of the entire transcript that includes a header for each subject that is talked about in the podcast and include 5 detailed bullets for each subject, try to stay away from generally saying what was talked about and instead focus on the specific details mentioned with some quotes and further information\"},\n",
    "                {\"role\": \"user\", \"content\": combined_message}\n",
    "            ]\n",
    "            )\n",
    "            print(second.choices[0].message.content)\n",
    "            \n",
    "            title = filename.replace('.txt', '')\n",
    "            if not os.path.isdir(\"summaries/\" + video_obj[title]['author']):\n",
    "                os.mkdir(\"summaries/\" + video_obj[title]['author'])\n",
    "                \n",
    "            f = open(\"summaries/\" + video_obj[title]['author'] + \"/\" + filename, \"w\")\n",
    "            f.write(first.choices[0].message.content + second.choices[0].message.content)\n",
    "            f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
