{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Address already in use\n",
      "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
      "On macOS, try disabling the 'AirPlay Receiver' service from System Preferences -> General -> AirDrop & Handoff.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from threading import Thread\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "posts = []\n",
    "\n",
    "@app.route('/posts', methods=['GET'])\n",
    "def get_posts():\n",
    "    return jsonify(posts)\n",
    "\n",
    "@app.route('/posts', methods=['POST'])\n",
    "def add_post():\n",
    "    print(\"hello\")\n",
    "    post_data = request.json\n",
    "    posts.append(post_data)\n",
    "    return jsonify(post_data), 201\n",
    "\n",
    "from werkzeug.serving import run_simple\n",
    "\n",
    "def run_app():\n",
    "    run_simple('localhost', 5000, app)\n",
    "\n",
    "# Then start the thread as before\n",
    "flask_thread = Thread(target=run_app)\n",
    "flask_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPEN_AI_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get video transcript or audio file if video has no captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from datetime import datetime\n",
    "def get_todays_date():\n",
    "    # Get today's date\n",
    "    today = datetime.now()\n",
    "    # Format the date as a string (e.g., \"2024-03-14\")\n",
    "    date_string = today.strftime(\"%Y-%m-%d\")\n",
    "    return date_string\n",
    "from pytube import YouTube\n",
    "from pytube import Playlist\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from datetime import date\n",
    "\n",
    "def create_transcripts(type, dated):\n",
    "    if (type == 1):\n",
    "        videos = open(\"inputs.txt\", \"r\")\n",
    "        video_obj = {}\n",
    "        directory_path = 'Transcripts'\n",
    "\n",
    "        # Get a list of all .txt file paths in the directory\n",
    "        txt_file_paths = glob.glob(os.path.join(directory_path, '*.txt'))\n",
    "\n",
    "        # Loop through the list and remove each .txt file\n",
    "        for file_path in txt_file_paths:\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {file_path}: {e}\")\n",
    "        for video in videos:\n",
    "            # Get YouTube video\n",
    "            yt = YouTube(video)\n",
    "            video_obj[yt.title] = { \"author\": yt.author, \"transcribed_on\": date.today() }\n",
    "            caption=YouTubeTranscriptApi.get_transcript(yt.video_id, languages=['en'])\n",
    "            # Get video transcription, if none exist, download audio (last stream is guaranteed English)\n",
    "            if not caption:\n",
    "                streams = yt.streams.filter(only_audio=True, file_extension=\"mp4\")\n",
    "                streams[-1].download(\"audio_files\")\n",
    "            else:\n",
    "                f = open(\"transcripts/\" + yt.title + \".txt\", \"w\")\n",
    "                for obj in caption:\n",
    "                    f.write(obj['text'])\n",
    "                f.close()\n",
    "            description = yt.description\n",
    "            if not os.path.isdir(\"key info/\" + video_obj[yt.title]['author']):\n",
    "                        os.mkdir(\"key info/\" + video_obj[yt.title]['author'])\n",
    "            print(\"hello\")           \n",
    "            t = open(\"key info/\" + video_obj[yt.title]['author'] + \"/\" + yt.title + \".txt\", \"w\")\n",
    "            if description is not None:\n",
    "                t.write(\"Title:\" + yt.title  + \"\\nAuthor: Lev Pollock\\nDate: \"+ get_todays_date() + \"\\nChannel: \" + video_obj[yt.title]['author'] + \"\\nDescription: \"+ description + \"\\n\")\n",
    "            else:\n",
    "                t.write(\"Title:\" + yt.title  + \"\\nAuthor: Lev Pollock\\nDate: \"+ get_todays_date() + \"\\nChannel: \" + video_obj[yt.title]['author']+ \"\\n\")\n",
    "            t.close()\n",
    "    else :\n",
    "        playlist = open(\"channels.txt\", \"r\")\n",
    "        \n",
    "        video_obj = {}\n",
    "        directory_path = 'Transcripts'\n",
    "\n",
    "        # Get a list of all .txt file paths in the directory\n",
    "        txt_file_paths = glob.glob(os.path.join(directory_path, '*.txt'))\n",
    "\n",
    "        # Loop through the list and remove each .txt file\n",
    "        for file_path in txt_file_paths:\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {file_path}: {e}\")\n",
    "        for channel in playlist:\n",
    "            print(channel)\n",
    "            c = Playlist(channel)\n",
    "            for url in c.video_urls:\n",
    "                print(url)\n",
    "create_transcripts(1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribe audio files (if they exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video_obj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m         f\u001b[39m.\u001b[39mwrite(result\u001b[39m.\u001b[39mdecode(sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mencoding)\u001b[39m.\u001b[39mstrip())\n\u001b[1;32m     30\u001b[0m         f\u001b[39m.\u001b[39mclose()\n\u001b[0;32m---> 32\u001b[0m \u001b[39mprint\u001b[39m(video_obj)        \n",
      "\u001b[0;31mNameError\u001b[0m: name 'video_obj' is not defined"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "audio_files = os.fsencode(\"audio_files\")\n",
    "\n",
    "for file in os.listdir(audio_files):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".mp4\"):\n",
    "        title = filename.replace(\".mp4\", \"\")\n",
    "\n",
    "        # convert mp4 file to wav (16-bit)\n",
    "        new_filename = title + \".wav\"\n",
    "        subprocess.run([\n",
    "            'ffmpeg',\n",
    "            '-i', os.path.join(\"audio_files\", filename),\n",
    "            '-ar', '16000',\n",
    "            '-ac', '1',\n",
    "            '-c:a', 'pcm_s16le',\n",
    "            os.path.join(\"audio_files\", new_filename)\n",
    "        ])\n",
    "\n",
    "        # call local whisper model\n",
    "        result = subprocess.check_output([\n",
    "            './main',\n",
    "            '-f', '../Podcast-Summarizer/audio_files/' + new_filename\n",
    "        ], cwd=\"../whisper.cpp\")\n",
    "\n",
    "        f = open(\"transcripts/\" + title + \".txt\", \"w\")\n",
    "        f.write(result.decode(sys.stdout.encoding).strip())\n",
    "        f.close()\n",
    "\n",
    "print(video_obj)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 26\u001b[0m\n\u001b[1;32m     17\u001b[0m content \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m (gpt4\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     19\u001b[0m     part \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mchat\u001b[39m.\u001b[39mcompletions\u001b[39m.\u001b[39mcreate(model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-4-turbo-preview\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     20\u001b[0m         messages\u001b[39m=\u001b[39m[\n\u001b[1;32m     21\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mYou are an investment analyst who has been tasked with summarizing podcast transcripts for your boss so he can make strategic investment decisions.\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     22\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mPlease summarize the following podcast transcript for your boss in as much detail as possible. you must focus on the key points discussed, including the main arguments, insights, and takeaways. Additionally, identify any interesting quotes or counter-arguments presented. Do not miss a single point discussed in the transcript\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     23\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: content},\n\u001b[1;32m     24\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mthere should be two sections in the output, the high level takeaways of each subject which includes key quotes, and then a detailed breakdown section as noted by the next prompt which dictates the schema of how the answer must be, try to stay away from generally saying what was talked about and instead focus on the specific details mentioned with some quotes and further information\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     25\u001b[0m    \u001b[39m#  {\"role\": \"user\", \"content\": \"it should include a section of high level key takeaways, some of which are crucial quotes but also include some specific takeaways from the whole thing - approximately 10 of them, then a section of a deep breakdown of the entire transcript that includes a header for each subject that is talked about in the podcast and include 5 detailed bullets for each subject, try to stay away from generally saying what was talked about and instead focus on the specific details mentioned with some quotes and further information\"},\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: combined_message},\n\u001b[1;32m     27\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39myou must ensure all topics are covered comprehensively according to the schema.\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     28\u001b[0m     ]\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m     \u001b[39m#print(first_part)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[39m#print(\"part done\")\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     final_string \u001b[39m=\u001b[39m final_string \u001b[39m+\u001b[39m part\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_message' is not defined"
     ]
    }
   ],
   "source": [
    "# Path to your 'transcripts' directory\n",
    "directory_path = 'transcripts'\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    final_string = \"\"\n",
    "    # Check if the file is a .txt file\n",
    "    if filename.endswith('.txt'):\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        file_path2 = os.path.join('other', 'example.txt')\n",
    "        # Open and read the file\n",
    "        example_file=open(file_path2, 'r')\n",
    "        gpt4 = 1\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            if (gpt4==1):\n",
    "                part = openai.chat.completions.create(model=\"gpt-4-turbo-preview\", \n",
    "                    messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an investment analyst who has been tasked with summarizing podcast transcripts for your boss so he can make strategic investment decisions.\"},\n",
    "                    {\"role\": \"user\", \"content\": \"Please summarize the following podcast transcript for your boss in as much detail as possible. you must focus on the key points discussed, including the main arguments, insights, and takeaways. Additionally, identify any interesting quotes or counter-arguments presented. Do not miss a single point discussed in the transcript\"},\n",
    "                    {\"role\": \"user\", \"content\": content},\n",
    "                    {\"role\": \"user\", \"content\": \"there should be two sections in the output, the high level takeaways of each subject which includes key quotes, and then a detailed breakdown section as noted by the next prompt which dictates the schema of how the answer must be, try to stay away from generally saying what was talked about and instead focus on the specific details mentioned with some quotes and further information\"},\n",
    "               #  {\"role\": \"user\", \"content\": \"it should include a section of high level key takeaways, some of which are crucial quotes but also include some specific takeaways from the whole thing - approximately 10 of them, then a section of a deep breakdown of the entire transcript that includes a header for each subject that is talked about in the podcast and include 5 detailed bullets for each subject, try to stay away from generally saying what was talked about and instead focus on the specific details mentioned with some quotes and further information\"},\n",
    "                    {\"role\": \"user\", \"content\": combined_message},\n",
    "                    {\"role\": \"user\", \"content\": \"you must ensure all topics are covered comprehensively according to the schema.\"}\n",
    "                ]\n",
    "                )\n",
    "                #print(first_part)\n",
    "                #print(\"part done\")\n",
    "                final_string = final_string + part.choices[0].message.content + \"\\n\"\n",
    "            else:\n",
    "                string_length = len(content)\n",
    "                multiple = string_length // 30000 + 1\n",
    "                div = string_length // multiple + multiple\n",
    "                print(div)\n",
    "                print(multiple)\n",
    "                first_part = content[:div]\n",
    "                second_part = content[div:]\n",
    "                full_string = \"\"\n",
    "                for x in range(1, multiple+1): \n",
    "                    print(x)\n",
    "                    combined_message = \"you must use the following as a schema for how you structure the output\" + \"\\n\" + example_file.read()\n",
    "                    #Split the string into two halves\n",
    "                    part = openai.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                        messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are an investment analyst who has been tasked with summarizing podcast transcripts for your boss so he can make strategic investment insights.\"},\n",
    "                        {\"role\": \"user\", \"content\": \"Please summarize the following podcast transcript for your boss in as much detail as possible. you must focus on the key points discussed, including the main arguments, insights, and takeaways. Additionally, identify any interesting quotes or counter-arguments presented. Please present in very detailed bullet point form, do not miss a single point discussed in the transcript\"},\n",
    "                        {\"role\": \"user\", \"content\": first_part},\n",
    "                        {\"role\": \"user\", \"content\": \"there should be two sections in the output, the high level takeaways of each subject which includes key quotes, and then a detailed breakdown section as noted by the next prompt, try to stay away from generally saying what was talked about and instead focus on the specific details mentioned with some quotes and further information\"},\n",
    "                    #  {\"role\": \"user\", \"content\": \"it should include a section of high level key takeaways, some of which are crucial quotes but also include some specific takeaways from the whole thing - approximately 10 of them, then a section of a deep breakdown of the entire transcript that includes a header for each subject that is talked about in the podcast and include 5 detailed bullets for each subject, try to stay away from generally saying what was talked about and instead focus on the specific details mentioned with some quotes and further information\"},\n",
    "                        {\"role\": \"user\", \"content\": combined_message},\n",
    "                        {\"role\": \"user\", \"content\": \"you must ensure all topics are covered comprehensively according to the schema.\"}\n",
    "                    ]\n",
    "                    )\n",
    "                    full_string = full_string + \"\\n\" + part.choices[0].message.content\n",
    "                    #print(part.choices[0].message.content)\n",
    "                    if (x!=1):\n",
    "                        new_part = openai.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                        messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are an investment analyst who has been tasked with summarizing podcast transcripts for your boss so he can make strategic investment insights.\"},\n",
    "                        {\"role\": \"user\", \"content\": \"Please combine the following two parts of a podcast summary into a single, cohesive document. You must ensure that the final summary is structured according to the specified schema with all relevant details maintained and properly integrated. The schema must be as follows:\"},\n",
    "                        {\"role\": \"user\", \"content\": combined_message},\n",
    "                        {\"role\": \"user\", \"content\": \"Here are the parts to combine, they are in the schema format as well:\"},\n",
    "                    #  {\"role\": \"user\", \"content\": \"it should include a section of high level key takeaways, some of which are crucial quotes but also include some specific takeaways from the whole thing - approximately 10 of them, then a section of a deep breakdown of the entire transcript that includes a header for each subject that is talked about in the podcast and include 5 detailed bullets for each subject, try to stay away from generally saying what was talked about and instead focus on the specific details mentioned with some quotes and further information\"},\n",
    "                        {\"role\": \"user\", \"content\": \"part 1: \" + part.choices[0].message.content},\n",
    "                        {\"role\": \"user\", \"content\": \"part 2: \" + final_string},\n",
    "                        {\"role\": \"user\", \"content\": \"you must ensure all topics are covered comprehensively according to the schema and that you maintain the two components of key highlights and detailed breakdown.\"}\n",
    "                        ]\n",
    "                        )\n",
    "                    #print(first_part)\n",
    "                    #print(\"part done\")\n",
    "                        final_string = new_part.choices[0].message.content\n",
    "                    else:\n",
    "                        final_string = part.choices[0].message.content\n",
    "                    first_part = second_part[:div]\n",
    "                    second_part = second_part[div:]\n",
    "            summary = openai.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": \"You are an investment analyst who has been tasked with summarizing podcast transcripts for your boss so he can make strategic investment insights.\"},\n",
    "                            {\"role\": \"user\", \"content\": \"Write a 100 word summary of this summary of a podcast\"},\n",
    "                            {\"role\": \"user\", \"content\": final_string}\n",
    "                        ]\n",
    "            )\n",
    "            final_string = \"Summary: \" + summary.choices[0].message.content + \"\\n\" + final_string \n",
    "            title = filename.split('.')[0]\n",
    "            if not os.path.isdir(\"summaries/\" + video_obj[title]['author']):\n",
    "                os.mkdir(\"summaries/\" + video_obj[title]['author'])\n",
    "            if not os.path.isdir(\"unorganized summaries/\" + video_obj[title]['author']):\n",
    "                os.mkdir(\"unorganized summaries/\" + video_obj[title]['author'])\n",
    "                \n",
    "            f = open(\"summaries/\" + video_obj[title]['author'] + \"/\" + filename, \"w\")\n",
    "            f.write(final_string)\n",
    "            f.close()\n",
    "            t = open(\"unorganized summaries/\" + video_obj[title]['author'] + \"/\" + filename, \"w\")\n",
    "            t.write(full_string)\n",
    "            t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Capital Allocators with Ted Seides: corresponding subdirectory does not exist in the second base directory.\n",
      "Skipping Capital Allocators with Ted Seides: corresponding subdirectory does not exist in the second base directory.\n",
      "Skipping David Rubenstein: corresponding subdirectory does not exist in the second base directory.\n",
      "File 2024 Macro Outlook Not Rosy - Expert Felix Zulauf Explains.txt does not exist in both directories under The Meb Faber Show Podcast.\n",
      "File BlackRock's Bond Chief: Lock That Bond Yield! | Rick Rieder.txt does not exist in both directories under The Meb Faber Show Podcast.\n",
      "Skipping Comic Doctor: corresponding subdirectory does not exist in the second base directory.\n",
      "Skipping Comic Doctor: corresponding subdirectory does not exist in the second base directory.\n",
      "Skipping FORMULA 1: corresponding subdirectory does not exist in the second base directory.\n",
      "Skipping FORMULA 1: corresponding subdirectory does not exist in the second base directory.\n",
      "Skipping FORMULA 1: corresponding subdirectory does not exist in the second base directory.\n",
      "Skipping Vox: corresponding subdirectory does not exist in the second base directory.\n",
      "Skipping Capital Allocators with Ted Seides: corresponding subdirectory does not exist in the second base directory.\n",
      "Skipping Capital Allocators with Ted Seides: corresponding subdirectory does not exist in the second base directory.\n",
      "Skipping MrBeast: corresponding subdirectory does not exist in the second base directory.\n",
      "All applicable files have been successfully combined and saved.\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Define the base directories\n",
    "base_dir2 = 'Summaries'\n",
    "base_dir1 = 'key info'\n",
    "output_base_dir = 'Word Files'\n",
    "\n",
    "# Ensure the output base directory exists\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "# Walk through all subdirectories and files in the first base directory\n",
    "for subdir, dirs, files in os.walk(base_dir1):\n",
    "    for filename in files:\n",
    "        # Construct the relative path\n",
    "        rel_path = os.path.relpath(subdir, base_dir1)\n",
    "        \n",
    "        # Check if the corresponding subdirectory exists in the second base directory\n",
    "        corresponding_subdir = os.path.join(base_dir2, rel_path)\n",
    "        if not os.path.exists(corresponding_subdir):\n",
    "            print(f\"Skipping {rel_path}: corresponding subdirectory does not exist in the second base directory.\")\n",
    "            continue  # Skip to the next file\n",
    "\n",
    "        # Construct the full paths for both source files\n",
    "        file_path1 = os.path.join(subdir, filename)\n",
    "        file_path2 = os.path.join(corresponding_subdir, filename)\n",
    "\n",
    "        # Check if the corresponding file exists in the second directory\n",
    "        if os.path.exists(file_path2):\n",
    "            doc = Document()\n",
    "\n",
    "            # Read and add the contents of the first file\n",
    "            with open(file_path1, 'r', encoding='utf-8') as file1:\n",
    "                content1 = file1.read()\n",
    "                doc.add_paragraph(content1)\n",
    "\n",
    "            # Read and add the contents of the second file\n",
    "            with open(file_path2, 'r', encoding='utf-8') as file2:\n",
    "                content2 = file2.read()\n",
    "                doc.add_paragraph(content2)\n",
    "\n",
    "            # Construct the output directory path and ensure it exists\n",
    "            output_dir = os.path.join(output_base_dir, rel_path)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            # Construct the output file path and save the combined content as a Word document\n",
    "            output_file_path = os.path.join(output_dir, os.path.splitext(filename)[0] + '.docx')\n",
    "            doc.save(output_file_path)\n",
    "        else:\n",
    "            print(f\"File {filename} does not exist in both directories under {rel_path}.\")\n",
    "base_dir2 = 'unorganized Summaries'\n",
    "base_dir1 = 'key info'\n",
    "output_base_dir = 'Word Files'\n",
    "\n",
    "# Ensure the output base directory exists\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "# Walk through all subdirectories and files in the first base directory\n",
    "for subdir, dirs, files in os.walk(base_dir1):\n",
    "    for filename in files:\n",
    "        # Construct the relative path\n",
    "        rel_path = os.path.relpath(subdir, base_dir1)\n",
    "        \n",
    "        # Check if the corresponding subdirectory exists in the second base directory\n",
    "        corresponding_subdir = os.path.join(base_dir2, rel_path)\n",
    "        if not os.path.exists(corresponding_subdir):\n",
    "            print(f\"Skipping {rel_path}: corresponding subdirectory does not exist in the second base directory.\")\n",
    "            continue  # Skip to the next file\n",
    "\n",
    "        # Construct the full paths for both source files\n",
    "        file_path1 = os.path.join(subdir, filename)\n",
    "        file_path2 = os.path.join(corresponding_subdir, filename)\n",
    "\n",
    "        # Check if the corresponding file exists in the second directory\n",
    "        if os.path.exists(file_path2):\n",
    "            doc = Document()\n",
    "\n",
    "            # Read and add the contents of the first file\n",
    "            with open(file_path1, 'r', encoding='utf-8') as file1:\n",
    "                content1 = file1.read()\n",
    "                doc.add_paragraph(content1)\n",
    "\n",
    "            # Read and add the contents of the second file\n",
    "            with open(file_path2, 'r', encoding='utf-8') as file2:\n",
    "                content2 = file2.read()\n",
    "                doc.add_paragraph(content2)\n",
    "\n",
    "            # Construct the output directory path and ensure it exists\n",
    "            output_dir = os.path.join(output_base_dir, rel_path)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            # Construct the output file path and save the combined content as a Word document\n",
    "            output_file_path = os.path.join(output_dir, os.path.splitext(filename)[0] +' unorganized.docx')\n",
    "            doc.save(output_file_path)\n",
    "        else:\n",
    "            print(f\"File {filename} does not exist in both directories under {rel_path}.\")\n",
    "\n",
    "# Notify the user that the process is complete\n",
    "print(\"All applicable files have been successfully combined and saved.\")\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
